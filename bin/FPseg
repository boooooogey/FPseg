#!/usr/bin/env python
from FPseg import Segmentor, GenomeReader
from FPseg import _pick_lambda
import argparse
import glob, os
from sklearn.mixture import BayesianGaussianMixture
from distinctipy import distinctipy
import subprocess

parser = argparse.ArgumentParser(description="Genome segmentation tool")
subs = parser.add_subparsers(dest="mode")

ta_parser = subs.add_parser("train-annotate")
ta_parser.add_argument("--bigwig-files", help="Directory where bigwig files are stored.", required=True)
ta_parser.add_argument("--training-bed", help="Bed file with segments to be included in training of the GMM model.", required=True)
ta_parser.add_argument("--target-bed", help="Bed file with segments to be annotated.", default=None)
ta_parser.add_argument("--chromosome-sizes", help="File containing chromosome sizes.", required=True)
ta_parser.add_argument("--lambda-list", help="File containing lambda values for each signal.", default=None)
ta_parser.add_argument("--lambda-window", help="Lenght of the data to use for Lambda selection.", type=int)
ta_parser.add_argument("--lambda-path", help="Path to write the selected lambdas.")
ta_parser.add_argument("--output", help="Path to write output.", required=True)
ta_parser.add_argument("--bin-size", help="Size of each bin.", type=int, default=200)
ta_parser.add_argument("--chunk-size", help="Size of each chunk.", type=int, default=10000000)
ta_parser.add_argument("--sample-size", help="Sample size from each chunk.", type=int, default=2000)
ta_parser.add_argument("--components", help="Number of components in the mixture model.", type=int, default=25)
ta_parser.add_argument("--noise-window", help="If data is noisy increase (default = 2).", type=int, default=2)
ta_parser.add_argument("--number-of-cores", help="The number of cpus to be used. (default = 4)", type=int, default=4)
ta_parser.add_argument("--init-params", help="", default="kmeans")
ta_parser.add_argument("--covariance-type", help="", default="full")
ta_parser.add_argument("--max-iter", help="", type=int, default=250)
ta_parser.add_argument("--random-state", help="", default=None)
ta_parser.add_argument("--weight-concentration-prior-type", help="", default="dirichlet_process")
ta_parser.add_argument("--verbose", help="Print information about progress of segmentation.", action="store_true")

btl_parser = subs.add_parser("bed-to-layered")
btl_parser.add_argument("--bed", help="The annotation bed.", required=True)
btl_parser.add_argument("--layered-bed", help="Path for the output layered BED.", required=True)
btl_parser.add_argument("--components", help="Number of components in the mixture model.", type=int, required=True)
btl_parser.add_argument("--chromosome-sizes", help="File containing chromosome sizes.", required=True)

def read_dictionary(path, f = (str,int)):
    with open(path) as file:
        tmp = file.readlines()
    tmp = [i.strip().split() for i in tmp]
    out = dict()
    for i in tmp:
        out[f[0](i[0])] = f[1](i[1])
    return out

def read_list(path, f = float):
    with open(path) as file:
        tmp = file.readlines()
    tmp = [f(i.strip()) for i in tmp] 
    return tmp

def read_bed(path):
    with open(path) as file:
        tmp = file.readlines()
    tmp = [i.strip().split() for i in tmp]
    tmp = [(i[0], int(i[1]), int(i[2])) for i in tmp]
    return tmp

def _hex_to_decimal(hexc):
    return f"{int(hexc[1:3],16)},{int(hexc[3:5],16)},{int(hexc[5:7],16)}"

def _get_distinct_colors(nlabels):
    colors = distinctipy.get_colors(nlabels)
    colors = [_hex_to_decimal(distinctipy.get_hex(i)) for i in colors]
    return colors

def _convert_bed_to_layered(path_bed, path_out, chromosome_sizes, n_components):
    colors = _get_distinct_colors(n_components)

    with open(path_bed) as file:
        a = file.readlines()
    a = [i.strip().split() for i in a[1:]]
    a = [[i[0], int(i[1]), int(i[2]), int(i[3])] for i in a]
    a = sorted(a, key = lambda x: x[0])

    with open(path_out, "w") as file:
        pass

    label_dict = dict()
    for i in range(n_components):
        label_dict[i] = {"start":[], "end":[]}

    curr_chromosome = a[0][0] 
    for i in range(len(a)):
        if curr_chromosome != a[i][0]:
            bbed = ""
            for l in range(n_components):
                if len(label_dict[l]["start"]) != 0:
                    if label_dict[l]["end"][-1] == chromosome_sizes[curr_chromosome]:
                        block_size = len(label_dict[l]["start"]) + 1
                        bed_start = "0," + ",".join([str(i) for i in label_dict[l]["start"]])
                        bed_sizes = "0," + ",".join([str(e-s) for s,e in zip(label_dict[l]["start"], label_dict[l]["end"])])
                    else:
                        block_size = len(label_dict[l]["start"]) + 2
                        bed_start = "0," + ",".join([str(i) for i in label_dict[l]["start"]]) + "," + str(chromosome_sizes[curr_chromosome]-1)
                        bed_sizes = "0," + ",".join([str(e-s) for s,e in zip(label_dict[l]["start"], label_dict[l]["end"])]) + ",1"
                else:
                    block_size = 2
                    bed_start = "0,"+ str(chromosome_sizes[curr_chromosome]-1)
                    bed_sizes = "0,1" 
                color = colors[l]
                bbed = bbed + curr_chromosome + "\t0\t" + str(chromosome_sizes[curr_chromosome]) + "\t" + str(l) + "\t1000\t.\t0\t" + str(chromosome_sizes[curr_chromosome]) + "\t" + color + "\t" + str(block_size) + "\t" + bed_sizes + "\t" + bed_start + "\n"
                label_dict[l]["start"] = []
                label_dict[l]["end"] = []
            with open(path_out,"a") as file:
                file.write(bbed)
            curr_chromosome = a[i][0]
        if len(label_dict[int(a[i][3])]["start"]) == 0:
            label_dict[int(a[i][3])]["start"].append(int(a[i][1]))
            label_dict[int(a[i][3])]["end"].append(int(a[i][2]))
        else:
            if label_dict[int(a[i][3])]["end"][-1] == int(a[i][1]):
                label_dict[int(a[i][3])]["end"][-1] = int(a[i][2])
            else:
                label_dict[int(a[i][3])]["start"].append(int(a[i][1]))
                label_dict[int(a[i][3])]["end"].append(int(a[i][2]))
    curr_chromosome = a[-1][0]
    bbed = ""
    for l in range(n_components):
        if len(label_dict[l]["start"]) != 0:
            if label_dict[l]["end"][-1] == chromosome_sizes[curr_chromosome]:
                block_size = len(label_dict[l]["start"]) + 1
                bed_start = "0," + ",".join([str(i) for i in label_dict[l]["start"]])
                bed_sizes = "0," + ",".join([str(e-s) for s,e in zip(label_dict[l]["start"], label_dict[l]["end"])])
            else:
                block_size = len(label_dict[l]["start"]) + 2
                bed_start = "0," + ",".join([str(i) for i in label_dict[l]["start"]]) + "," + str(chromosome_sizes[curr_chromosome]-1)
                bed_sizes = "0," + ",".join([str(e-s) for s,e in zip(label_dict[l]["start"], label_dict[l]["end"])]) + ",1"
        else:
            block_size = 2
            bed_start = "0,"+ str(chromosome_sizes[curr_chromosome]-1)
            bed_sizes = "0,1" 
        color = colors[l]
        bbed = bbed + curr_chromosome + "\t0\t" + str(chromosome_sizes[curr_chromosome]) + "\t" + str(l) + "\t1000\t.\t0\t" + str(chromosome_sizes[curr_chromosome]) + "\t" + color + "\t" + str(block_size) + "\t" + bed_sizes + "\t" + bed_start + "\n"
        label_dict[l]["start"] = []
        label_dict[l]["end"] = []
    with open(path_out,"a") as file:
        file.write(bbed)

args = parser.parse_args()

#args.noise_window

if args.mode == "train-annotate":

    if args.target_bed is None:
        target_bed = None
    else:
        target_bed = read_bed(args.target_bed)

    training_bed = read_bed(args.training_bed)
    if args.lambda_list is not None:
        lambda_list = read_list(args.lambda_list)
    chromosome_sizes = read_dictionary(args.chromosome_sizes)

    bwfiles = sorted(glob.glob(os.path.join(args.bigwig_files,"*.bw")))

    gmm =  BayesianGaussianMixture(n_components=args.components, random_state=args.random_state, max_iter=args.max_iter, covariance_type=args.covariance_type, init_params=args.init_params, weight_concentration_prior_type=args.weight_concentration_prior_type, verbose=args.verbose)

    reader = GenomeReader(bwfiles)

    if args.lambda_list is None:
        lambda_list = _pick_lambda(reader, training_bed[0][0], args.lambda_window, args.bin_size, verbose = args.verbose, path = args.lambda_path) 

    segmentor = Segmentor(reader, gmm, lambda_list, args.components, chromosome_sizes, bin_size = args.bin_size, chunk_size = args.chunk_size, number_of_sample = args.sample_size, number_of_cores = args.number_of_cores)

    segmentor.fit(training_bed, verbose=args.verbose)

    segmentor.predict(args.output, target = target_bed, verbose = args.verbose)

elif args.mode == "bed-to-layered":

    chromosome_sizes = read_dictionary(args.chromosome_sizes)

    layered_bed_name = os.path.join(os.path.dirname(args.bed), os.path.basename(args.bed)[:-4] + "_layered.bed")

    print(f"Writing layered format into {layered_bed_name}")

    _convert_bed_to_layered(args.bed, layered_bed_name, chromosome_sizes, args.components)

    print(f"Converting layered bed into binary bigBed: {args.layered_bed}")

    subprocess.run(["bedToBigBed", layered_bed_name, args.chromosome_sizes, args.layered_bed])

else:
    raise ValueError("Unknown mode.")
